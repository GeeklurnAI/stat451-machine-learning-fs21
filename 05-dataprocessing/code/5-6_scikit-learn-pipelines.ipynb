{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0fa450b-13b2-4c32-9dd1-ae60a44e8225",
   "metadata": {},
   "source": [
    "STAT 451: Machine Learning (Fall 2021)  \n",
    "Instructor: Sebastian Raschka (sraschka@wisc.edu)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d2da68-18e9-4c45-9158-2cdeb29a6981",
   "metadata": {
    "tags": []
   },
   "source": [
    "# L05 - Data Preprocessing and Machine Learning with Scikit-Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60abc6b-9f90-42ff-9735-c17a3980114c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 5.6 Scikit-Learn Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202cc3ae-b00b-40db-b936-c151fdaf66ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size (96, 4) class proportions [32 32 32]\n",
      "Valid size (24, 4) class proportions [8 8 8]\n",
      "Test size (30, 4) class proportions [10 10 10]\n"
     ]
    }
   ],
   "source": [
    "# Code repeated from 5-2-basic-data-handling.ipynb\n",
    "# and 5-5_preparing-training-data.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/iris.csv')\n",
    "\n",
    "d = {'Iris-setosa': 0,\n",
    "     'Iris-versicolor': 1,\n",
    "     'Iris-virginica': 2}\n",
    "df['Species'] = df['Species'].map(d)\n",
    "\n",
    "X = df.iloc[:, 1:5].values\n",
    "y = df['Species'].values\n",
    "\n",
    "\n",
    "X_temp, X_test, y_temp, y_test = \\\n",
    "        train_test_split(X, y, test_size=0.2, \n",
    "                         shuffle=True, random_state=123, stratify=y)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "        train_test_split(X_temp, y_temp, test_size=0.2,\n",
    "                         shuffle=True, random_state=123, stratify=y_temp)\n",
    "\n",
    "print('Train size', X_train.shape, 'class proportions', np.bincount(y_train))\n",
    "print('Valid size', X_valid.shape, 'class proportions', np.bincount(y_valid))\n",
    "print('Test size', X_test.shape, 'class proportions', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b142243f-fd24-45d9-bde2-a35b1573f0ca",
   "metadata": {},
   "source": [
    "## Feature Transformation, Extraction, and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e62b8a6-1740-413c-a2fc-e570481c42a8",
   "metadata": {},
   "source": [
    "We have already covered very simple cases of feature transformation, i.e., normalization, that is, min-max scaling and standardization. There are many other cases, but an extensive coverage of feature preprocessing is beyond the scope of a machine learning class. However, we will will look at some popular feature selection (sequential feature selection) and feature extraction (e.g., principal component analysis) techniques later in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397cb733-fb3a-4e1a-9434-466350964dc6",
   "metadata": {},
   "source": [
    "## Scikit-Learn Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d28a31-fa6a-4d51-b90c-90d4fb2f57c1",
   "metadata": {},
   "source": [
    "- Scikit-learn pipelines are an extremely convenient and powerful concept -- one of the things that sets scikit-learn apart from other machine learning libraries.\n",
    "- Pipelines basically let us define a series of perprocessing steps together with fitting an estimator.\n",
    "- Pipelines will automatically take care of pitfalls like estimating feature scaling parameters from the training set and applying those to scale new data (which we discussed earlier in the context of z-score standardization).\n",
    "- Below is an visualization of how pipelines work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d2f3f-5de2-4901-ac40-cf83d62a07f8",
   "metadata": {},
   "source": [
    "<img src=\"images/sklearn-pipeline.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee462d38-9bc2-44a8-88a1-ec1ef4c5e57e",
   "metadata": {},
   "source": [
    "- Below is an example pipeline that combines the feature scaling step with the *k*NN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e39c1c30-f0d9-4e8c-a1d9-a18192871221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier(n_neighbors=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b45f5165-69ab-4815-8679-f07912c464e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=3))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a59fb47-9c46-47b7-8ef4-ad933c83c402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 2, 1, 2, 1, 0, 0, 0, 0, 0, 2,\n",
       "       2, 1, 2, 2, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6acd616-cc74-43ea-a734-bb55bdc0fc67",
   "metadata": {},
   "source": [
    "- As you can see above, the Pipeline itself follows the scikit-learn estimator API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1cff6-f682-46e0-b78a-e72b162030f7",
   "metadata": {},
   "source": [
    "(Also see the [FunctionTransformer](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html) in scikit-learn, which allows creating a transformer class from an arbitrary callable or function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb6b3ca-39f1-467e-9712-dca99fab5429",
   "metadata": {},
   "source": [
    "## Intro Model Selection -- Pipelines and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a579d86-b8fa-4ad1-b2e8-cb887eb335ba",
   "metadata": {},
   "source": [
    "- In machine learning practice, we often need to experiment with an machine learning algorithm's hyperparameters to find a good setting.\n",
    "- The process of tuning hyperparameters and comparing and selecting the resulting models is also called \"model selection\" (in contrast to \"algorithm selection\").\n",
    "- We will cover topics such as \"model selection\" and \"algorithm selection\" in more detail later in this course.\n",
    "- For now, we are introducing the simplest way of performing model selection: using the \"holdout method.\"\n",
    "- In the holdout method, we split a dataset into 3 subsets: a training, a validation, and a test datatset.\n",
    "- To avoid biasing the estimate of the generalization performance, we only want to use the test dataset once, which is why we use the validation dataset for hyperparameter tuning (model selection).\n",
    "- Here, the validation dataset serves as an estimate of the generalization performance, too, but it becomes more biased than the final estimate on the test data because of its repeated re-use during model selection (think of \"multiple hypothesis testing\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1c220d-4a07-4105-b1d1-d6cf9d68f757",
   "metadata": {},
   "source": [
    "<img src=\"images/holdout-tuning.png\" alt=\"drawing\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77a5a25e-5d95-4387-ad00-46601aa2e8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<mlxtend.evaluate.holdout.PredefinedHoldoutSplit object at 0x147cf82b0>,\n",
       "             estimator=Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                                       ('kneighborsclassifier',\n",
       "                                        KNeighborsClassifier())]),\n",
       "             param_grid={'kneighborsclassifier__n_neighbors': [1, 3, 5],\n",
       "                         'kneighborsclassifier__p': [1, 2]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from mlxtend.evaluate import PredefinedHoldoutSplit\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "train_ind, valid_ind = train_test_split(np.arange(X.shape[0]),\n",
    "                                        test_size=0.2, shuffle=True,\n",
    "                                        random_state=123, stratify=y)\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     KNeighborsClassifier())\n",
    "\n",
    "params = {'kneighborsclassifier__n_neighbors': [1, 3, 5],\n",
    "          'kneighborsclassifier__p': [1, 2]}\n",
    "\n",
    "split = PredefinedHoldoutSplit(valid_indices=valid_ind)\n",
    "\n",
    "grid = GridSearchCV(pipe,\n",
    "                    param_grid=params,\n",
    "                    cv=split)\n",
    "\n",
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c527f342-2ccc-4849-946f-416906692d21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00041103, 0.00032616, 0.00029635, 0.00029206, 0.00029492,\n",
       "        0.00028801]),\n",
       " 'std_fit_time': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'mean_score_time': array([0.00054908, 0.00048995, 0.0004909 , 0.00053   , 0.00048995,\n",
       "        0.0004828 ]),\n",
       " 'std_score_time': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'param_kneighborsclassifier__n_neighbors': masked_array(data=[1, 1, 3, 3, 5, 5],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kneighborsclassifier__p': masked_array(data=[1, 2, 1, 2, 1, 2],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'kneighborsclassifier__n_neighbors': 1,\n",
       "   'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 1, 'kneighborsclassifier__p': 2},\n",
       "  {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 3, 'kneighborsclassifier__p': 2},\n",
       "  {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 1},\n",
       "  {'kneighborsclassifier__n_neighbors': 5, 'kneighborsclassifier__p': 2}],\n",
       " 'split0_test_score': array([0.9       , 0.96666667, 0.96666667, 0.93333333, 0.9       ,\n",
       "        0.9       ]),\n",
       " 'mean_test_score': array([0.9       , 0.96666667, 0.96666667, 0.93333333, 0.9       ,\n",
       "        0.9       ]),\n",
       " 'std_test_score': array([0., 0., 0., 0., 0., 0.]),\n",
       " 'rank_test_score': array([4, 1, 1, 3, 4, 4], dtype=int32)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2465a996-4008-417e-8a55-a0c2af663f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n",
      "{'kneighborsclassifier__n_neighbors': 1, 'kneighborsclassifier__p': 2}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0411dd28-f289-4799-9296-7dc23a805063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "clf = grid.best_estimator_\n",
    "clf.fit(X_train, y_train)\n",
    "print('Test accuracy: %.2f%%' % (clf.score(X_test, y_test)*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit ('base': conda)",
   "language": "python",
   "name": "python392jvsc74a57bd0249cfc85c6a0073df6bca89c83e3180d730f84f7e1f446fbe710b75104ecfa4f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
